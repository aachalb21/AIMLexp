# -*- coding: utf-8 -*-
"""Copy of Experiment no 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZuUAI6cqbvjZt-79PBLEy7nlvUULOapx

Importing the libraries and dataset
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

dataset = pd.read_csv('/content/drive/MyDrive/Btech sem 7 lab/Honours/data.csv')

dataset.head()

"""Data Exploration"""

dataset.shape

dataset.info()

dataset.select_dtypes(include='object').columns

len(dataset.select_dtypes(include='object').columns)

dataset.select_dtypes(include=['float64','int64']).columns

len(dataset.select_dtypes(include=['float64','int64']).columns)

#statistical summary
dataset.describe()

dataset.columns

"""Dealing with the missing values"""

dataset.isnull().values.any()

dataset.isnull().values.sum()

dataset.columns[dataset.isnull().any()]

len(dataset.columns[dataset.isnull().any()])

dataset['Unnamed: 32'].count()

dataset = dataset.drop(columns='Unnamed: 32')

dataset.shape

dataset.isnull().values.any()

"""Dealing with categorical data"""

dataset.select_dtypes(include='object').columns

dataset['diagnosis'].unique()

dataset['diagnosis'].nunique()

# one hot encoding
#dataset = pd.get_dummies(data=dataset)
dataset = pd.get_dummies(data=dataset, drop_first=True)

dataset.head()

# B (0) values
(dataset.diagnosis_M == 0).sum()

# M (1) values
(dataset.diagnosis_M == 1).sum()

"""Correlation matrix and heatmap"""

dataset_2 = dataset.drop(columns='diagnosis_M')

dataset_2.head()

# Correlation matrix
corr = dataset.corr()

corr

# heatmap
plt.figure(figsize=(20,10))
sns.heatmap(corr, annot=True)

fig, ax = plt.subplots(figsize=(100,100))
sns.boxplot(data=dataset, width= 0.5,ax=ax,  fliersize=3)

"""Splitting the dataset train and test set"""

dataset.head()

# matrix of features / independent variables
x = dataset.iloc[:, 1:-1].values    #x = dataset.drop(['diagnosis_M'],axis=1)

x.shape

# target variable / dependent variable
y = dataset.iloc[:, -1].values   #y = dataset['diagnosis_M']

y.shape

from sklearn.model_selection import  train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)

x_train.shape

x_test.shape

y_train.shape

y_test.shape

"""Feature scaling"""

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()

x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

x_train

x_test

"""Building the model

1) logistic regression
"""

from sklearn.linear_model import LogisticRegression

from sklearn.linear_model import LogisticRegression
classifir_lr = LogisticRegression(random_state = 0)

classifir_lr.fit(x_train, y_train)

from sklearn.impute import SimpleImputer

# Create an imputer to replace NaN values with the mean of each column
imputer = SimpleImputer(strategy='mean')

# Fit and transform x_train
x_train = imputer.fit_transform(x_train)

# Also apply the same transformation to x_test (if applicable)
x_test = imputer.transform(x_test)

classifier_lr.fit(x_train, y_train)

import pandas as pd

# If x_train is a DataFrame
x_train = pd.DataFrame(x_train)
y_train = pd.Series(y_train)

# Drop rows where any feature is NaN
non_nan_indices = ~x_train.isnull().any(axis=1)
x_train = x_train[non_nan_indices]
y_train = y_train[non_nan_indices]

classifier_lr.fit(x_train, y_train)

y_pred = classifir_lr.predict(x_test)

from sklearn.linear_model import LogisticRegression
from sklearn.impute import SimpleImputer

# Handle NaNs
imputer = SimpleImputer(strategy='mean')
x_train = imputer.fit_transform(x_train)
x_test = imputer.transform(x_test)

# Define and train model
classifier_lr = LogisticRegression()
classifier_lr.fit(x_train, y_train)  # Must call fit before predict

# Predict
y_pred = classifier_lr.predict(x_test)

from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score

acc = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
prec = precision_score(y_test, y_pred)
rec = recall_score(y_test, y_pred)

results = pd.DataFrame([['Logistic Regression', acc, f1, prec, rec]],
               columns = ['Model', 'Accuracy', 'F1 Score', 'Precision', 'Recall'])

results

cm = confusion_matrix(y_test, y_pred)
print(cm)

